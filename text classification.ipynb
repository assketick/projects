{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы будем работать с датасетом постов из твиттера. Нам предстоит решать задачу бинарной классификации - определять содержатся ли в твитте информация о настоящей катастрофе/инциденте или нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1 (0.5 балла)\n",
    "\n",
    "Выведете на экран информацию о пропусках в данных. Если пропуски присутствуют заполните их пустой строкой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id             0\n",
       "keyword       61\n",
       "location    2533\n",
       "text           0\n",
       "target         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пропуски присутствуют только в колонках \"keyword\" и \"location\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(data, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2 (1 балл)\n",
    "Давайте немного посмотрим на наши данные. Визуализируйте (где явно просят) или выведете информацию о следующем:\n",
    "\n",
    "1. Какое распределение классов в обучающей выборке?\n",
    "2. Посмотрите на колонку \"keyword\" - возьмите 10 наиболее встречающихся значений, постройте ступенчатую диаграмму распределения классов в зависимости от значения keyword, сделайте выводы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3024\n",
       "1    2305\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.target.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0-вого класса примерно на 700 больше. Распределение можно назвать равномерным"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = np.array(train['keyword'].value_counts().index[:10])\n",
    "dct = dict(list(zip(lst, np.arange(10))))\n",
    "v0 = np.zeros(10)\n",
    "v1 = np.zeros(10)\n",
    "for value in train[['keyword', 'target']].values:\n",
    "    if value[0] in dct:\n",
    "        if value[1] == 0:\n",
    "            v0[dct[value[0]]] += 1\n",
    "        else:\n",
    "            v1[dct[value[0]]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame({0: v0, 1: v1})\n",
    "df.plot(kind='bar')\n",
    "plt.xticks(np.arange(10), lst)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чем чаще встречается \"ключевое слово\", тем больше вероятность положительного прогноза"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 3 (0.5 балла) \n",
    "\n",
    "В этом задании предлагается объединить все три текстовых столбца в один (просто сконкатенировать cтроки) и убрать столбец с индексом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train['union'] = data[data.columns[1:4]].apply(lambda x: ' '.join(x), axis=1)\n",
    "train = train.drop(columns=['id', 'keyword', 'location', 'text'])\n",
    "\n",
    "test['union'] = data[data.columns[1:4]].apply(lambda x: ' '.join(x), axis=1)\n",
    "test = test.drop(columns=['id', 'keyword', 'location', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>union</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1186</th>\n",
       "      <td>bridge%20collapse  Ashes 2015: AustraliaÛªs c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4071</th>\n",
       "      <td>hail Carol Stream, Illinois GREAT MICHIGAN TEC...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5461</th>\n",
       "      <td>police Houston  CNN: Tennessee movie theater s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5787</th>\n",
       "      <td>rioting  Still rioting in a couple of hours le...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7445</th>\n",
       "      <td>wounds Lake Highlands Crack in the path where ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5226</th>\n",
       "      <td>obliteration Merica! @Eganator2000 There aren'...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>panic  just had a panic attack bc I don't have...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>blood  Omron HEM-712C Automatic Blood Pressure...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7603</th>\n",
       "      <td>Officials say a quarantine is in place at an...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7270</th>\n",
       "      <td>whirlwind Stamford &amp; Cork (&amp; Shropshire) I mov...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5329 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  union  target\n",
       "1186  bridge%20collapse  Ashes 2015: AustraliaÛªs c...       0\n",
       "4071  hail Carol Stream, Illinois GREAT MICHIGAN TEC...       1\n",
       "5461  police Houston  CNN: Tennessee movie theater s...       1\n",
       "5787  rioting  Still rioting in a couple of hours le...       1\n",
       "7445  wounds Lake Highlands Crack in the path where ...       0\n",
       "...                                                 ...     ...\n",
       "5226  obliteration Merica! @Eganator2000 There aren'...       0\n",
       "5390  panic  just had a panic attack bc I don't have...       0\n",
       "860   blood  Omron HEM-712C Automatic Blood Pressure...       0\n",
       "7603    Officials say a quarantine is in place at an...       1\n",
       "7270  whirlwind Stamford & Cork (& Shropshire) I mov...       1\n",
       "\n",
       "[5329 rows x 2 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.reindex(['union', 'target'], axis=\"columns\")\n",
    "test.reindex(['union', 'target'], axis=\"columns\")\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train['target']\n",
    "x_train = train['union']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = test['union']\n",
    "y_test = test['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 4 (0.5 балла)\n",
    "\n",
    "Далее мы будем пока работать только с train частью.\n",
    "\n",
    "1. Предобработайте данные (train часть) с помощью CountVectorizer.\n",
    "2. Какого размера получилась матрица?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cnt_vec = CountVectorizer()\n",
    "x_train_transformed = cnt_vec.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "↓↓↓Размер матрицы↓↓↓"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5329, 18455)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_transformed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 5 (1 балл)\n",
    "\n",
    "В предыдущем пункте у вас должна была получиться достаточно большая матрица.\n",
    "Если вы взгляните на текст, то увидете, что там есть множество специальных символов, ссылок и прочего мусора.\n",
    "\n",
    "Давайте также посмотрим на словарь, который получился в результате построения CountVectorizer, его можно найти в поле vocabulary_ инстанса этого класса. Давайте напишем функцию, которая печает ответы на следующие вопросы:\n",
    "\n",
    "1. Найдите в этом словаре все слова, которые содержат цифры. Сколько таких слов нашлось?\n",
    "\n",
    "2. Найдите все слова, которые содержат символы пунктуации. Сколько таких слов нашлось? \n",
    "\n",
    "3. Сколько хэштегов (токен начинается на #) и упоминаний (токен начинается на @) осталось в словаре?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bridge': 2948,\n",
       " '20collapse': 320,\n",
       " 'ashes': 1928,\n",
       " '2015': 295,\n",
       " 'australia': 2059,\n",
       " 'ûªs': 18425,\n",
       " 'collapse': 3914,\n",
       " 'at': 1977,\n",
       " 'trent': 16483,\n",
       " 'among': 1628,\n",
       " 'worst': 17813,\n",
       " 'in': 8314,\n",
       " 'history': 7773,\n",
       " 'england': 5722,\n",
       " 'bundled': 3085,\n",
       " 'out': 11995,\n",
       " 'for': 6503,\n",
       " '60': 755,\n",
       " 'http': 7970,\n",
       " 'co': 3861,\n",
       " 't5trhjuau0': 15733,\n",
       " 'hail': 7420,\n",
       " 'carol': 3363,\n",
       " 'stream': 15419,\n",
       " 'illinois': 8249,\n",
       " 'great': 7206,\n",
       " 'michigan': 10594,\n",
       " 'technique': 15888,\n",
       " 'camp': 3261,\n",
       " 'b1g': 2147,\n",
       " 'thanks': 16013,\n",
       " 'to': 16272,\n",
       " 'bmurph1019': 2753,\n",
       " 'hail_youtsey': 7421,\n",
       " 'termn8r13': 15949,\n",
       " 'goblue': 7088,\n",
       " 'wrestleon': 17848,\n",
       " 'oaskgki6qj': 11648,\n",
       " 'police': 12634,\n",
       " 'houston': 7933,\n",
       " 'cnn': 3854,\n",
       " 'tennessee': 15932,\n",
       " 'movie': 10940,\n",
       " 'theater': 16025,\n",
       " 'shooting': 14647,\n",
       " 'suspect': 15632,\n",
       " 'killed': 9246,\n",
       " 'by': 3150,\n",
       " 'di8elzswnr': 4890,\n",
       " 'rioting': 13800,\n",
       " 'still': 15357,\n",
       " 'couple': 4204,\n",
       " 'of': 11708,\n",
       " 'hours': 7925,\n",
       " 'left': 9644,\n",
       " 'until': 16884,\n",
       " 'have': 7546,\n",
       " 'be': 2383,\n",
       " 'up': 16895,\n",
       " 'class': 3774,\n",
       " 'wounds': 17822,\n",
       " 'lake': 9485,\n",
       " 'highlands': 7724,\n",
       " 'crack': 4242,\n",
       " 'the': 16022,\n",
       " 'path': 12228,\n",
       " 'where': 17582,\n",
       " 'wiped': 17684,\n",
       " 'this': 16107,\n",
       " 'morning': 10886,\n",
       " 'during': 5348,\n",
       " 'beach': 2386,\n",
       " 'run': 14049,\n",
       " 'surface': 15606,\n",
       " 'on': 11828,\n",
       " 'elbow': 5571,\n",
       " 'and': 1651,\n",
       " 'right': 13783,\n",
       " 'knee': 9316,\n",
       " 'yaqrsximph': 18081,\n",
       " 'airplane': 1458,\n",
       " '20accident': 309,\n",
       " 'somewhere': 15025,\n",
       " 'there': 16070,\n",
       " 'experts': 5988,\n",
       " 'france': 6594,\n",
       " 'begin': 2442,\n",
       " 'examining': 5934,\n",
       " 'debris': 4641,\n",
       " 'found': 6553,\n",
       " 'reunion': 13707,\n",
       " 'island': 8601,\n",
       " 'french': 6642,\n",
       " 'air': 1451,\n",
       " 'accident': 1241,\n",
       " 'tagzbcxfj0': 15758,\n",
       " 'mlb': 10762,\n",
       " 'bloody': 2719,\n",
       " 'isolated': 8610,\n",
       " 'city': 3742,\n",
       " 'world': 17794,\n",
       " 'perth': 12370,\n",
       " 'came': 3251,\n",
       " 'kill': 9243,\n",
       " 'indians': 8356,\n",
       " 'fun': 6721,\n",
       " 'video': 17164,\n",
       " 'smirking': 14922,\n",
       " 'remorseless': 13579,\n",
       " 'pakistani': 12124,\n",
       " 'killer': 9247,\n",
       " 'shows': 14678,\n",
       " 'him': 7746,\n",
       " 'boasting': 2766,\n",
       " 'fpjlwoxklg': 6575,\n",
       " 'burning': 3101,\n",
       " 'johnsontionne': 8903,\n",
       " 'except': 5939,\n",
       " 'idk': 8176,\n",
       " 'them': 16055,\n",
       " 'it': 8620,\n",
       " 'really': 13423,\n",
       " 'destroy': 4823,\n",
       " 'he': 7580,\n",
       " 'or': 11919,\n",
       " 'she': 14590,\n",
       " 'her': 7670,\n",
       " 'ask': 1943,\n",
       " 'house': 7926,\n",
       " 'wounded': 17821,\n",
       " 'maracay': 10278,\n",
       " 'nirgua': 11374,\n",
       " 'venezuela': 17104,\n",
       " 'officer': 11725,\n",
       " 'dead': 4615,\n",
       " 'after': 1395,\n",
       " 'exchanging': 5943,\n",
       " 'shots': 14660,\n",
       " 'xxfk4khbiw': 18027,\n",
       " 'wreck': 17845,\n",
       " 'currently': 4410,\n",
       " 'writing': 17858,\n",
       " 'book': 2805,\n",
       " 'friggin': 6666,\n",
       " 'destiel': 4817,\n",
       " 'sucks': 15514,\n",
       " 'read': 13402,\n",
       " 'vine': 17185,\n",
       " 'description': 4797,\n",
       " 'https': 7971,\n",
       " 'mkx6ux4ozt': 10760,\n",
       " 'mudslide': 10998,\n",
       " 'malibu': 10234,\n",
       " 'santafe': 14210,\n",
       " 'winning': 17679,\n",
       " 'sterling': 15340,\n",
       " 'scott': 14326,\n",
       " 'red': 13475,\n",
       " 'carpet': 3368,\n",
       " 'fundraiser': 6724,\n",
       " 'oso': 11969,\n",
       " 'ma4ra7atql': 10151,\n",
       " 'cg579wldne': 3513,\n",
       " 'casualties': 3406,\n",
       " 'canadian': 3282,\n",
       " 'bread': 2915,\n",
       " 'libertarianluke': 9733,\n",
       " 'all': 1539,\n",
       " 'that': 16016,\n",
       " 'honest': 7859,\n",
       " 'if': 8187,\n",
       " 'people': 12330,\n",
       " 'want': 17376,\n",
       " 'go': 7080,\n",
       " 'rampage': 13313,\n",
       " 'let': 9698,\n",
       " 'use': 16955,\n",
       " 'their': 16050,\n",
       " 'own': 12051,\n",
       " 'hands': 7465,\n",
       " 'feet': 6221,\n",
       " 'no': 11417,\n",
       " 'ambulance': 1608,\n",
       " 'amsterdam': 1635,\n",
       " '7xglah10zl': 928,\n",
       " 'twelve': 16646,\n",
       " 'feared': 6198,\n",
       " 'helicopter': 7646,\n",
       " 'crash': 4257,\n",
       " 'thmblaatzp': 16115,\n",
       " 'electrocuted': 5585,\n",
       " 'got': 7141,\n",
       " 'last': 9543,\n",
       " 'night': 11359,\n",
       " 'work': 17784,\n",
       " 'first': 6348,\n",
       " 'time': 16206,\n",
       " 'my': 11069,\n",
       " 'life': 9746,\n",
       " 'shit': 14630,\n",
       " 'was': 17406,\n",
       " 'weird': 17514,\n",
       " 'drown': 5276,\n",
       " 'some': 15013,\n",
       " 'older': 11801,\n",
       " 'native': 11173,\n",
       " 'australians': 2061,\n",
       " 'believe': 2469,\n",
       " 'oceans': 11685,\n",
       " 'were': 17532,\n",
       " 'created': 4278,\n",
       " 'from': 6673,\n",
       " 'urine': 16932,\n",
       " 'an': 1638,\n",
       " 'angry': 1676,\n",
       " 'god': 7090,\n",
       " 'who': 17605,\n",
       " 'tried': 16503,\n",
       " 'volcano': 17257,\n",
       " 'west': 17537,\n",
       " 'coast': 3869,\n",
       " 'cali': 3226,\n",
       " 'usa': 16943,\n",
       " 'architect': 1834,\n",
       " 'behind': 2454,\n",
       " 'kanye': 9086,\n",
       " 'musbik7ejf': 11030,\n",
       " 'attack': 2002,\n",
       " 'mumbai': 11017,\n",
       " 'india': 8349,\n",
       " 'shud': 14684,\n",
       " 'not': 11481,\n",
       " 'give': 7013,\n",
       " 'any': 1734,\n",
       " 'evidence': 5919,\n",
       " 'pak': 12122,\n",
       " 'they': 16089,\n",
       " 'will': 17641,\n",
       " 'share': 14573,\n",
       " 'with': 17700,\n",
       " 'terrorists': 15962,\n",
       " 'amp': 1630,\n",
       " 'next': 11313,\n",
       " 'oth': 11977,\n",
       " 'contries': 4114,\n",
       " 'qiopbtiuvu': 13126,\n",
       " 'body': 2774,\n",
       " '20bag': 311,\n",
       " 'new': 11281,\n",
       " 'york': 18173,\n",
       " 'auth': 2063,\n",
       " 'louis': 9993,\n",
       " 'vuitton': 17294,\n",
       " 'brown': 3002,\n",
       " 'saumur': 14245,\n",
       " '35': 485,\n",
       " 'cross': 4322,\n",
       " 'shoulder': 14662,\n",
       " 'bag': 2202,\n",
       " 'monogram': 10842,\n",
       " '23': 355,\n",
       " '419': 581,\n",
       " 'full': 6718,\n",
       " 'û_': 18408,\n",
       " 'hcdiwe5flc': 7571,\n",
       " 'zlvebeoavg': 18338,\n",
       " 'annihilated': 1696,\n",
       " 'higher': 7721,\n",
       " 'places': 12532,\n",
       " 'episode': 5783,\n",
       " 'trunks': 16557,\n",
       " 'freiza': 6640,\n",
       " 'is': 8585,\n",
       " 'cleanest': 3782,\n",
       " 'ever': 5902,\n",
       " 'showed': 14674,\n",
       " 'nigga': 11357,\n",
       " 'mercy': 10518,\n",
       " 'cyclone': 4447,\n",
       " 'hyderabad': 8073,\n",
       " 'roughdeal1': 13969,\n",
       " 'ante': 1714,\n",
       " 'hudhud': 7978,\n",
       " 'chandrababu': 3544,\n",
       " 'valle': 17039,\n",
       " 'ne': 11224,\n",
       " 'ga': 6799,\n",
       " '65': 781,\n",
       " 'zhenghxn': 18312,\n",
       " '11': 117,\n",
       " 'eyes': 6036,\n",
       " 'akame': 1474,\n",
       " 'tokyo': 16296,\n",
       " 'ghoul': 6978,\n",
       " 'damn': 4511,\n",
       " 'dont': 5154,\n",
       " 'dare': 4551,\n",
       " 'watch': 17423,\n",
       " 'suicide': 15530,\n",
       " '20bombing': 317,\n",
       " 'principality': 12842,\n",
       " 'zeron': 18304,\n",
       " 'rayquazaerk': 13368,\n",
       " 'are': 1836,\n",
       " 'christian': 3689,\n",
       " 'sure': 15600,\n",
       " 'but': 3126,\n",
       " 'don': 5144,\n",
       " 'bombing': 2794,\n",
       " 'employed': 5668,\n",
       " 'often': 11746,\n",
       " 'as': 1912,\n",
       " 'islamic': 8598,\n",
       " 'groups': 7259,\n",
       " 'demolished': 4739,\n",
       " 'jackmulholland1': 8698,\n",
       " 'think': 16099,\n",
       " 'also': 1581,\n",
       " 'became': 2412,\n",
       " 'marquis': 10322,\n",
       " 'then': 16062,\n",
       " 'carlos': 3355,\n",
       " 'charlie': 3569,\n",
       " 'finally': 6308,\n",
       " 'dublin': 5308,\n",
       " 'sadly': 14130,\n",
       " 'inundated': 8515,\n",
       " 'surf': 15604,\n",
       " 'hi': 7711,\n",
       " 'waimea': 17339,\n",
       " 'bay': 2344,\n",
       " 'like': 9769,\n",
       " 'surfers': 15607,\n",
       " 'czdw8oowa2': 4460,\n",
       " 'collision': 3928,\n",
       " 'denver': 4763,\n",
       " 'colorado': 3939,\n",
       " 'motorcyclist': 10919,\n",
       " 'bicyclist': 2564,\n",
       " 'injured': 8415,\n",
       " 'broadway': 2984,\n",
       " 'zl7ojdaj3u': 18334,\n",
       " 'flames': 6386,\n",
       " 'around': 1879,\n",
       " 'you': 18177,\n",
       " 'maryland': 10334,\n",
       " 'mansion': 10268,\n",
       " 'fire': 6330,\n",
       " 'caused': 3434,\n",
       " 'damaged': 4502,\n",
       " 'plug': 12586,\n",
       " 'under': 16813,\n",
       " 'christmas': 3696,\n",
       " 'tree': 16469,\n",
       " 'report': 13616,\n",
       " 'says': 14264,\n",
       " 'into': 8509,\n",
       " 'lkjfabqzb3': 9869,\n",
       " 'demolish': 4738,\n",
       " 'nyhc': 11603,\n",
       " 'going': 7098,\n",
       " 'drake': 5213,\n",
       " 'over': 12023,\n",
       " 'ghostwriting': 6977,\n",
       " 'should': 14661,\n",
       " 'know': 9331,\n",
       " 'rihanna': 13788,\n",
       " 'lives': 9847,\n",
       " 'door': 5158,\n",
       " 'buildings': 3066,\n",
       " '20burning': 319,\n",
       " 'blue': 2736,\n",
       " 'yes': 18118,\n",
       " '1acd4900c1424d1': 232,\n",
       " 'foxnews': 6567,\n",
       " 'one': 11834,\n",
       " 'down': 5182,\n",
       " 'looting': 9961,\n",
       " 'forest': 6518,\n",
       " '20fires': 327,\n",
       " 'nicola': 11345,\n",
       " 'valley': 17040,\n",
       " 'fires': 6343,\n",
       " 'dying': 5384,\n",
       " 'salmon': 14165,\n",
       " 'act': 1279,\n",
       " 'deny': 4764,\n",
       " 'climate': 3805,\n",
       " 'change': 3545,\n",
       " 'nightmares': 11362,\n",
       " 'here': 7671,\n",
       " 'rbzomwgjee': 13380,\n",
       " 'bcpoli': 2375,\n",
       " 'canpoli': 3300,\n",
       " 'vanpoli': 17056,\n",
       " 'ns1aggfnxz': 11533,\n",
       " 'shoes': 14642,\n",
       " 'asics': 1940,\n",
       " 'gt': 7281,\n",
       " 'ii': 8217,\n",
       " 'super': 15573,\n",
       " 'ronnie': 13935,\n",
       " 'fieg': 6275,\n",
       " 'kith': 9287,\n",
       " 'white': 17599,\n",
       " '3m': 536,\n",
       " 'gel': 6908,\n",
       " 'grey': 7233,\n",
       " 'od250zshfy': 11689,\n",
       " 'sandstorm': 14201,\n",
       " 'airport': 1460,\n",
       " 'get': 6950,\n",
       " 'swallowed': 15645,\n",
       " 'minute': 10695,\n",
       " 'wd9odwjj9l': 17467,\n",
       " '20on': 331,\n",
       " '20fire': 326,\n",
       " 'uk': 16776,\n",
       " 'tweetlikeitsseptember11th2001': 16643,\n",
       " 'those': 16126,\n",
       " 'two': 16658,\n",
       " 'oil': 11769,\n",
       " '20spill': 338,\n",
       " 'ny': 11592,\n",
       " 'california': 3229,\n",
       " 'spill': 15149,\n",
       " 'might': 10622,\n",
       " 'larger': 9535,\n",
       " 'than': 16005,\n",
       " 'projected': 12889,\n",
       " 'xwxbyhtuzc': 18026,\n",
       " 'wzedxefblg': 17918,\n",
       " 'cartoon': 3380,\n",
       " 'bears': 2394,\n",
       " 'without': 17705,\n",
       " 'we': 17472,\n",
       " 'would': 17817,\n",
       " 'qave': 13098,\n",
       " 'knowlddge': 9333,\n",
       " 'toilet': 16293,\n",
       " 'paper': 12162,\n",
       " 'drought': 5271,\n",
       " 'miami': 10585,\n",
       " '_gaabyx': 1137,\n",
       " 'purple': 13035,\n",
       " 'activist': 1291,\n",
       " 'thought': 16129,\n",
       " 'injuries': 8417,\n",
       " 'madison': 10177,\n",
       " 'wi': 17620,\n",
       " 'st': 15242,\n",
       " 'mo': 10781,\n",
       " 'buffoonmike': 3060,\n",
       " 'knew': 9320,\n",
       " 'doing': 5128,\n",
       " 'much': 10995,\n",
       " 'bite': 2628,\n",
       " 'us': 16939,\n",
       " 'influenced': 8398,\n",
       " 'shitty': 14634,\n",
       " 'staff': 15251,\n",
       " 'acquisitions': 1274,\n",
       " 'landslide': 9511,\n",
       " 'austin': 2058,\n",
       " 'texas': 15977,\n",
       " 'toddstarnes': 16285,\n",
       " 'enjoy': 5729,\n",
       " 'impending': 8289,\n",
       " 'todd': 16283,\n",
       " 'hehe': 7632,\n",
       " 'apocalypse': 1768,\n",
       " 'oregon': 11935,\n",
       " 'look': 9946,\n",
       " 'grizzly': 7245,\n",
       " 'peak': 12297,\n",
       " 'now': 11512,\n",
       " 'looks': 9950,\n",
       " 'beginning': 2444,\n",
       " 'dystopian': 5389,\n",
       " 'detonation': 4841,\n",
       " 'ignition': 8203,\n",
       " 'knock': 9326,\n",
       " 'sensor': 14469,\n",
       " 'senso': 14468,\n",
       " 'standard': 15264,\n",
       " 'ks100': 9383,\n",
       " '7o4lnfbe7k': 920,\n",
       " 'fvzsgjtbew': 6753,\n",
       " '20responders': 334,\n",
       " 'week': 17505,\n",
       " 'responders': 13667,\n",
       " 'dart': 4564,\n",
       " 'members': 10495,\n",
       " 'participating': 12201,\n",
       " 'four': 6558,\n",
       " 'day': 4593,\n",
       " 'intensive': 8481,\n",
       " 'technical': 15886,\n",
       " 'large': 9534,\n",
       " 'animal': 1678,\n",
       " 'tl93aod3er': 16247,\n",
       " 'military': 10641,\n",
       " 'lot': 9984,\n",
       " '20': 281,\n",
       " 'tom': 16302,\n",
       " 'clancy': 3770,\n",
       " 'mystery': 11085,\n",
       " 'novels': 11510,\n",
       " 'paperback': 12163,\n",
       " 'obix79ncxn': 11654,\n",
       " 'tomclancy': 16306,\n",
       " 'drowning': 5278,\n",
       " 'coventry': 4216,\n",
       " 'why': 17618,\n",
       " 'low': 10009,\n",
       " 'self': 14439,\n",
       " 'image': 8264,\n",
       " 'take': 15766,\n",
       " 'quiz': 13198,\n",
       " 'z8r6r3nbtb': 18264,\n",
       " 'namffldh5h': 11138,\n",
       " 'gonna': 7110,\n",
       " 'fight': 6284,\n",
       " 'taylor': 15834,\n",
       " 'soon': 15044,\n",
       " 'danger': 4525,\n",
       " 'hailing': 7424,\n",
       " 'dayton': 4595,\n",
       " 'wish': 17695,\n",
       " 'could': 4190,\n",
       " 'victoria': 17154,\n",
       " 'secret': 14399,\n",
       " 'front': 6674,\n",
       " 'good': 7111,\n",
       " 'flood': 6428,\n",
       " 'spot': 15181,\n",
       " 'combo': 3950,\n",
       " '53inch': 689,\n",
       " '300w': 459,\n",
       " 'curved': 4414,\n",
       " 'cree': 4288,\n",
       " 'led': 9634,\n",
       " 'light': 9757,\n",
       " 'bar': 2268,\n",
       " '4x4': 659,\n",
       " 'offroad': 11739,\n",
       " 'fog': 6467,\n",
       " 'lamp': 9493,\n",
       " 're': 13389,\n",
       " 'o097vsotxk': 11619,\n",
       " 'i23xy7iejj': 8089,\n",
       " 'severe': 14522,\n",
       " 'weather': 17486,\n",
       " 'bulletin': 3073,\n",
       " 'typhoon': 16684,\n",
       " 'ûï': 18429,\n",
       " 'hannaph': 7473,\n",
       " 'soudelor': 15063,\n",
       " 'tropical': 16532,\n",
       " 'warning': 17391,\n",
       " 'issued': 8615,\n",
       " '00': 0,\n",
       " 'pm': 12594,\n",
       " '06': 23,\n",
       " 'thhjjw51pe': 16092,\n",
       " 'fits': 6357,\n",
       " '01': 6,\n",
       " 'bmw': 2754,\n",
       " '325ci': 478,\n",
       " '5l': 726,\n",
       " 'l6': 9449,\n",
       " 'gbvdnczjou': 6893,\n",
       " 'c211hise0r': 3169,\n",
       " 'explosion': 6003,\n",
       " 'london': 9928,\n",
       " 'united': 16851,\n",
       " 'kingdom': 9267,\n",
       " '10': 87,\n",
       " 'chemical': 3605,\n",
       " 'park': 12186,\n",
       " 'western': 17541,\n",
       " 'germany': 6945,\n",
       " 'xbznu0qkvs': 17948,\n",
       " 'bomb': 2789,\n",
       " 'soul': 15065,\n",
       " 'food': 6488,\n",
       " 'sound': 15069,\n",
       " 'so': 14969,\n",
       " 'terrorism': 15960,\n",
       " 'truth': 16561,\n",
       " 'bejftygjil': 2461,\n",
       " 'news': 11295,\n",
       " 'bbc': 2353,\n",
       " 'islam': 8595,\n",
       " 'isis': 8593,\n",
       " 'quran': 13207,\n",
       " 'lies': 9745,\n",
       " 'jlczidz7vu': 8866,\n",
       " 'sinking': 14765,\n",
       " 'your': 18187,\n",
       " 'lost': 9983,\n",
       " 'alone': 1569,\n",
       " 'stone': 15374,\n",
       " 'carry': 3373,\n",
       " 'onå': 11862,\n",
       " 'hostage': 7911,\n",
       " 'chicago': 3624,\n",
       " 'mylittlepwnies3': 11080,\n",
       " 'early__may': 5428,\n",
       " 'anathemazhiv': 1645,\n",
       " 'tonysandos': 16320,\n",
       " 'which': 17587,\n",
       " 'has': 7522,\n",
       " 'do': 5103,\n",
       " 'lebanon': 9631,\n",
       " '80s': 943,\n",
       " 'iran': 8561,\n",
       " 'crisis': 4311,\n",
       " 'libya': 9740,\n",
       " 'pan': 12140,\n",
       " 'am': 1595,\n",
       " 'pa': 12092,\n",
       " 'pulls': 13002,\n",
       " 'gun': 7315,\n",
       " 'man': 10245,\n",
       " 'apparent': 1779,\n",
       " 'provocation': 12948,\n",
       " 'lhw4vtbhzg': 9729,\n",
       " 'via': 17141,\n",
       " 'dailykos': 4488,\n",
       " 'derailment': 4784,\n",
       " 'minneapolis': 10684,\n",
       " 'mn': 10776,\n",
       " 'train': 16424,\n",
       " 'patna': 12236,\n",
       " 'casualty': 3407,\n",
       " 'far': 6130,\n",
       " 'indian': 8352,\n",
       " 'express': 6011,\n",
       " 'yh5vetm0yz': 18131,\n",
       " '17wgug8z0m': 197,\n",
       " 'panic': 12151,\n",
       " 'dream': 5228,\n",
       " 'magic': 10189,\n",
       " 'linden': 9791,\n",
       " 'method': 10548,\n",
       " 'lite': 9821,\n",
       " 'version': 17119,\n",
       " 'anxiety': 1733,\n",
       " 'cure': 4403,\n",
       " 'program': 12880,\n",
       " '073izwx0lb': 28,\n",
       " 'lind': 9789,\n",
       " 'okmlagvkjv': 11790,\n",
       " 'rescued': 13638,\n",
       " 'jammu': 8730,\n",
       " 'kashmir': 9098,\n",
       " 'delhi': 4711,\n",
       " '18': 198,\n",
       " 'bovines': 2849,\n",
       " 'smugglersåênabbed': 14936,\n",
       " 'e7fn5g5ruu': 5411,\n",
       " 'fredericksburg': 6615,\n",
       " 'virginia': 17202,\n",
       " 'wwp': 17901,\n",
       " 'serving': 14504,\n",
       " 'more': 10873,\n",
       " '75k': 881,\n",
       " 'veterans': 17126,\n",
       " '52k': 684,\n",
       " 'oif': 11768,\n",
       " 'oef': 11702,\n",
       " 'vets': 17127,\n",
       " 'physical': 12441,\n",
       " 'many': 10271,\n",
       " 'invisible': 8530,\n",
       " 'ones': 11840,\n",
       " 'shhlv4dplz': 14610,\n",
       " 'client': 3801,\n",
       " 'dust': 5351,\n",
       " '20storm': 339,\n",
       " 'learned': 9622,\n",
       " 'about': 1209,\n",
       " 'economics': 5479,\n",
       " 'south': 15079,\n",
       " 'dakota': 4492,\n",
       " 'storm': 15389,\n",
       " 'did': 4909,\n",
       " 'years': 18101,\n",
       " 'college': 3922,\n",
       " 'hubert': 7977,\n",
       " 'humphrey': 8012,\n",
       " 'wrecked': 17847,\n",
       " 'cramer': 4250,\n",
       " 'iger': 8195,\n",
       " 'words': 17783,\n",
       " 'disney': 5008,\n",
       " 'stock': 15365,\n",
       " 'sf5jdnvdw9': 14534,\n",
       " 'til_now': 16200,\n",
       " 'cnbc': 3849,\n",
       " 'tring': 16510,\n",
       " 'marc_holl': 10281,\n",
       " 'nennicook': 11260,\n",
       " 'aitchkaycee': 1465,\n",
       " 'vixstuart': 17228,\n",
       " 'benjbeckwith': 2497,\n",
       " 'pretty': 12817,\n",
       " 'disaster': 4979,\n",
       " 'gbbo': 6886,\n",
       " 'obliteration': 11663,\n",
       " 'canada': 3280,\n",
       " 'need': 11240,\n",
       " 'arcade': 1832,\n",
       " 'shooter': 14646,\n",
       " 'fix': 6362,\n",
       " 'cte': 4367,\n",
       " 'empty': 5673,\n",
       " 'only': 11850,\n",
       " 'running': 14056,\n",
       " 'even': 5896,\n",
       " 'buy': 3138,\n",
       " 'cod': 3885,\n",
       " 'title': 16234,\n",
       " 'weren': 17533,\n",
       " 'overpriced': 12032,\n",
       " 'steam': 15324,\n",
       " 'bioterrorism': 2609,\n",
       " 'firepower': 6342,\n",
       " 'lab': 9462,\n",
       " 'electronic': 5586,\n",
       " 'resource': 13659,\n",
       " 'automation': 2075,\n",
       " 'against': 1409,\n",
       " 'infectious': 8386,\n",
       " 'diseases': 4998,\n",
       " 'kvpbybglsr': 9415,\n",
       " 'graysondolan': 7201,\n",
       " 'me': 10434,\n",
       " 'explode': 5995,\n",
       " 'washington': 17412,\n",
       " 'kendall': 9160,\n",
       " 'jenner': 8806,\n",
       " 'nick': 11339,\n",
       " 'jonas': 8915,\n",
       " 'dating': 4573,\n",
       " 'quite': 13196,\n",
       " 'literally': 9822,\n",
       " 'pfvzvpxqgr': 12399,\n",
       " 'always': 1594,\n",
       " 'tell': 15913,\n",
       " 'mom': 10823,\n",
       " 'bring': 2963,\n",
       " 'hold': 7813,\n",
       " 'cat': 3408,\n",
       " 'heat': 7616,\n",
       " '20wave': 342,\n",
       " 'fort': 6540,\n",
       " 'worth': 17816,\n",
       " 'rt': 14016,\n",
       " 'startelegram': 15290,\n",
       " 'homeless': 7842,\n",
       " 'vulnerable': 17297,\n",
       " 'north': 11463,\n",
       " 'wave': 17440,\n",
       " 'k9airfq3ql': 9049,\n",
       " 'jdbtlymehy': 8790,\n",
       " 'nuclear': 11547,\n",
       " '20reactor': 333,\n",
       " 'solar': 14997,\n",
       " 'power': 12718,\n",
       " 'japanese': 8748,\n",
       " 'fukushima': 6717,\n",
       " 'reactor': 13399,\n",
       " 'energy': 5710,\n",
       " 'japan': 8747,\n",
       " 'temperature': 15924,\n",
       " 'fuel': 6710,\n",
       " 'pool': 12655,\n",
       " 'ys3nmwwyvc': 18215,\n",
       " 'alpotnb7q3': 1574,\n",
       " 'arvada': 1908,\n",
       " 'least': 9626,\n",
       " 'taken': 15769,\n",
       " 'local': 9900,\n",
       " 'wlmsq3mtho': 17725,\n",
       " 'trauma': 16451,\n",
       " 'nashville': 11161,\n",
       " 'tn': 16264,\n",
       " 'esteemed': 5852,\n",
       " 'journalist': 8936,\n",
       " 'recalls': 13445,\n",
       " 'tragic': 16420,\n",
       " 'effects': 5529,\n",
       " 'unaddressed': 16797,\n",
       " 'childhood': 3636,\n",
       " 'keithboykin': 9149,\n",
       " 'randallpinkston': 13317,\n",
       " 'pozarmy': 12723,\n",
       " 'gxq1auzb18': 7362,\n",
       " 'panicking': 12152,\n",
       " 'feel': 6213,\n",
       " 'results': 13689,\n",
       " 'back': 2179,\n",
       " 'alarmingly': 1498,\n",
       " 'calm': 3236,\n",
       " 'lightning': 9763,\n",
       " 'thunder': 16168,\n",
       " 'possible': 12689,\n",
       " 'pinpoint': 12479,\n",
       " 'foothill': 6502,\n",
       " 'forecast': 6511,\n",
       " 'ctijdpxabk': 4369,\n",
       " 'displaced': 5019,\n",
       " '40': 562,\n",
       " 'ocean': 11684,\n",
       " 'township': 16385,\n",
       " 'apartment': 1756,\n",
       " 'newyork': 11308,\n",
       " 'uelz59wvom': 16749,\n",
       " 'massacre': 10345,\n",
       " 'stay': 15315,\n",
       " 'tuned': 16602,\n",
       " 'freddiedeboer': 6612,\n",
       " 'thucydiplease': 16166,\n",
       " 'rise': 13810,\n",
       " 'coates': 3874,\n",
       " 'charleston': 3568,\n",
       " 'walter': 17366,\n",
       " 'black': 2652,\n",
       " 'twitter': 16656,\n",
       " 'broadly': 2982,\n",
       " 'well': 17519,\n",
       " 'deaths': 4636,\n",
       " 'gallifrey': 6826,\n",
       " 'mathew_is_angry': 10366,\n",
       " 'z3ke_sk1': 18256,\n",
       " 'saladinahmed': 14154,\n",
       " 'died': 4915,\n",
       " 'horrible': 7898,\n",
       " 'trapped': 16448,\n",
       " 'ships': 14624,\n",
       " 'risk': 13813,\n",
       " '20buildings': 318,\n",
       " 'whiterun': 17601,\n",
       " 'skyrim': 14840,\n",
       " 'destruction': 4829,\n",
       " 'fine': 6315,\n",
       " 'just': 9003,\n",
       " 'windstorm': 17667,\n",
       " 'palm': 12132,\n",
       " 'county': 4202,\n",
       " 'fl': 6379,\n",
       " 'reality': 13418,\n",
       " 'training': 16426,\n",
       " 'falls': 6103,\n",
       " 'off': 11716,\n",
       " 'elevated': 5597,\n",
       " 'tracks': 16405,\n",
       " 'jiomnrcygt': 8854,\n",
       " 'paramedic': 12173,\n",
       " 'ems': 5675,\n",
       " 'rescuers': 13639,\n",
       " 'fears': 6199,\n",
       " 'missing': 10721,\n",
       " 'migrants': 10625,\n",
       " 'med': 10448,\n",
       " 'search': 14378,\n",
       " 'survivors': 15627,\n",
       " 'boat': 2767,\n",
       " 'carrying': 3375,\n",
       " '6ds67xai5e': 810,\n",
       " 'derailed': 4782,\n",
       " 'toronto': 16346,\n",
       " 'derailed_benchmark': 4783,\n",
       " 'cool': 4127,\n",
       " 'paths': 12232,\n",
       " 'wonder': 17762,\n",
       " 'can': 3277,\n",
       " 'find': 6312,\n",
       " 'leaks': 9619,\n",
       " 'jobs': 8885,\n",
       " 'given': 7016,\n",
       " 'resque': 13673,\n",
       " 'too': 16321,\n",
       " 'ladies': 9473,\n",
       " 'tote': 16362,\n",
       " 'handbag': 7458,\n",
       " 'women': 17757,\n",
       " 'faux': 6162,\n",
       " 'leather': 9627,\n",
       " 'fashion': 6144,\n",
       " 'purse': 13040,\n",
       " 'y87gi3brlv': 18057,\n",
       " '1zbhvdcxzs': 280,\n",
       " 'raishimi33': 13302,\n",
       " 'sounds': 15073,\n",
       " 'plan': 12537,\n",
       " 'little': 9827,\n",
       " 'applaud': 1785,\n",
       " 'catastrophic': 3414,\n",
       " 'buxton': 3137,\n",
       " 'venice': 17105,\n",
       " 'nottingham': 11502,\n",
       " 'invading': 8518,\n",
       " 'iraq': 8566,\n",
       " 'mistake': 10730,\n",
       " 'diplomacy': 4951,\n",
       " 'needs': 11244,\n",
       " 'replace': 13611,\n",
       " 'constant': 4084,\n",
       " 'threat': 16137,\n",
       " 'war': 17380,\n",
       " 'israel': 8612,\n",
       " 'yqjpn3quux': 18205,\n",
       " 'related': 13543,\n",
       " 'threatens': 16140,\n",
       " 'europe': 5881,\n",
       " 'wk6b5z803o': 17720,\n",
       " 'livingston': 9852,\n",
       " 'mt': 10982,\n",
       " 'marynmck': 10335,\n",
       " 'beyond': 2537,\n",
       " 'adorable': 1334,\n",
       " 'hope': 7882,\n",
       " 'won': 17761,\n",
       " 'been': 2431,\n",
       " 'noticed': 11491,\n",
       " 'devastation': 4849,\n",
       " 'mount': 10923,\n",
       " 'vernon': 17115,\n",
       " 'coming': 3962,\n",
       " 'target': 15803,\n",
       " 'starbucks': 15279,\n",
       " 'closed': 3819,\n",
       " 'momneedscoffee': 10827,\n",
       " 'asap': 1915,\n",
       " 'iwontmakeit': 8651,\n",
       " 'bombed': 2791,\n",
       " 'screwston': 14353,\n",
       " 'tx': 16664,\n",
       " 'redskins': 13491,\n",
       " 'wr': 17838,\n",
       " 'roberts': 13868,\n",
       " 'belly': 2478,\n",
       " 'teamstream': 15877,\n",
       " 'gbcvvevdty': 6887,\n",
       " 'hellfire': 7650,\n",
       " 'allah': 1540,\n",
       " 'describes': 4795,\n",
       " 'piling': 12470,\n",
       " 'wealth': 17478,\n",
       " 'thinking': 16100,\n",
       " 'forever': 6519,\n",
       " 'surah': 15599,\n",
       " 'humaza': 8003,\n",
       " 'reflect': 13505,\n",
       " 'worldwide': 17802,\n",
       " 'loved': 9998,\n",
       " 'way': 17445,\n",
       " 'written': 17861,\n",
       " 'include': 8327,\n",
       " 'vantage': 17057,\n",
       " 'points': 12625,\n",
       " 'detkenlang': 4838,\n",
       " 'kindle': 9259,\n",
       " 'kcrnmjkj73': 9131,\n",
       " 'heartdisease': 7609,\n",
       " 'service': 14501,\n",
       " 'spending': 15140,\n",
       " 'half': 7436,\n",
       " 'budget': 3052,\n",
       " 'kzfigkeeva': 9434,\n",
       " 'tragedy': 16419,\n",
       " 'sandrabland': 14200,\n",
       " 'forget': 6522,\n",
       " 'gajtugaui7': 6817,\n",
       " 'mayhem': 10395,\n",
       " 'detroit': 4842,\n",
       " 'liked': 9770,\n",
       " 'youtube': 18195,\n",
       " 'itsjustinstuart': 8632,\n",
       " 'mnkaji2q1n': 10777,\n",
       " 'range': 13325,\n",
       " 'hungerarticles': 8019,\n",
       " 'nepal': 11264,\n",
       " 'rebuilding': 13440,\n",
       " 'livelihoods': 9839,\n",
       " 'quake': 13161,\n",
       " 'lrouwjmbix': 10026,\n",
       " 'arsonist': 1892,\n",
       " 'suspected': 15633,\n",
       " 'serial': 14492,\n",
       " 'arrested': 1882,\n",
       " 'calif': 3228,\n",
       " 'pzotpdgaki': 13075,\n",
       " 'hurricane': 8036,\n",
       " 'vineyard': 17187,\n",
       " 'chubbysquirrel_': 3702,\n",
       " 'hurricane_surge': 8039,\n",
       " ...}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt_vec.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(voc):\n",
    "    count_n = 0\n",
    "    for elem in voc:\n",
    "        if any(map(str.isdigit, elem)) == True:\n",
    "            count_n += 1\n",
    "    count_p = 0\n",
    "    for elem in voc:\n",
    "        if any(map(lambda x: x in punctuation, elem)) == True:\n",
    "            count_p += 1\n",
    "    ls = ['#', '@']\n",
    "    count_h = 0\n",
    "    for elem in voc:\n",
    "        if any(map(lambda x: x in ls, elem)) == True:\n",
    "            count_h += 1\n",
    "\n",
    "    print(\"Слов содержащих цифры -\", count_n)\n",
    "    print(\"Слов содержащих символы пунктуации -\", count_p)\n",
    "    print(\"Слов содержищих @ и # -\", count_h)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Слов содержащих цифры - 3812\n",
      "Слов содержащих символы пунктуации - 315\n",
      "Слов содержищих @ и # - 0\n"
     ]
    }
   ],
   "source": [
    "func(cnt_vec.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 6 (0.5 балла)\n",
    "\n",
    "Вспомним, что на семинаре по текстам мы узнали, что в nltk есть специальный токенизатор для текстов - TweetTokenizer. Попробуем применить CountVectorizer с этим токенизатором. Ответьте на все вопросы из предыдущего пункта для TweetTokenizer и сравните результаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "# Чтобы узнать, какие параметры есть у этого токенайзера - используйте help(TweetTokenizer)\n",
    "# Для того, чтобы передать токенайзер в CountVectorizer используйте параметр tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tw_vec = CountVectorizer(tokenizer=TweetTokenizer().tokenize)\n",
    "x_train_transformed = tw_vec.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Слов содержащих цифры - 3939\n",
      "Слов содержащих символы пунктуации - 7338\n",
      "Слов содержищих @ и # - 3155\n"
     ]
    }
   ],
   "source": [
    "func(tw_vec.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Появилось больше слов, содержащих цифры, также число слов с символами пунктуации сильно возросло. Добавились слова с \"@\" и \"#\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 7 (2 балла)\n",
    "\n",
    "В scikit-learn мы можем оценивать процесс подсчета матрицы через CountVectorizer. У CountVectorizer, как и у других наследников \\_VectorizerMixin, есть аргумент tokenizer и preprocessor. preprocessor применится в самом начале к каждой строке вашего датасета, tokenizer же должен принять строку и вернуть токены.\n",
    "Давайте напишем кастомный токенайзер, которые сделает все, что нам нужно: \n",
    "\n",
    "0. Приведет все буквы к нижнему регистру\n",
    "1. Разобьет текст на токены с помощью TweetTokenizer из пакета nltk\n",
    "2. Удалит все токены содержащие не латинские буквы, кроме смайликов (будем считать ими токены содержащие только пунктуацию и, как минимум, одну скобочку) и хэштегов, которые после начальной # содержат только латинские буквы.\n",
    "3. Удалит все токены, которые перечислены в nltk.corpus.stopwords.words('english')\n",
    "4. Проведет стемминг с помощью SnowballStemmer\n",
    "\n",
    "Продемонстрируйте работу вашей функции на первых десяти текстах в обучающей выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mytokenize(text):\n",
    "    lw_text = text.lower()\n",
    "\n",
    "    tw = TweetTokenizer()\n",
    "    tw_text = tw.tokenize(lw_text)\n",
    "\n",
    "    def test(word):\n",
    "        return re.fullmatch('[a-z]+|#[a-z]+|[' + punctuation + ']+[()][' + punctuation + ']*|[' + punctuation + ']*[()][' + punctuation + ']+', word) \n",
    "\n",
    "    tk_text = [word for word in tw_text if test(word)]\n",
    "    tk_text = [word for word in tk_text if word not in stopwords.words('english')]\n",
    "\n",
    "    stemmer = SnowballStemmer(language='english')\n",
    "    new_text = [stemmer.stem(w) for w in tk_text]\n",
    "                            \n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bridg', 'ash', 'australia', 'collaps', 'trent', 'bridg', 'among', 'worst', 'histori', 'england', 'bundl', 'australia']\n",
      "['hail', 'carol', 'stream', 'illinoi', 'great', 'michigan', 'techniqu', 'camp', 'thank', '#goblu', '#wrestleon']\n",
      "['polic', 'houston', 'cnn', 'tennesse', 'movi', 'theater', 'shoot', 'suspect', 'kill', 'polic']\n",
      "['riot', 'still', 'riot', 'coupl', 'hour', 'left', 'class']\n",
      "['wound', 'lake', 'highland', 'crack', 'path', 'wipe', 'morn', 'beach', 'run', 'surfac', 'wound', 'left', 'elbow', 'right', 'knee']\n",
      "['airplan', 'somewher', 'expert', 'franc', 'begin', 'examin', 'airplan', 'debri', 'found', 'reunion', 'island', 'french', 'air', 'accid', 'expert', '#mlb']\n",
      "['bloodi', 'isol', 'citi', 'world', 'perth', 'came', 'kill', 'indian', 'fun', 'video', 'smirk', 'remorseless', 'pakistani', 'killer', 'show', 'boast']\n",
      "['burn', 'except', 'idk', 'realli', 'burn']\n",
      "['destroy', 'ask', 'destroy', 'hous']\n",
      "['wound', 'maracay', 'nirgua', 'venezuela', 'polic', 'offic', 'wound', 'suspect', 'dead', 'exchang', 'shot']\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(mytokenize(x_train.iloc[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 8 (1 балл)\n",
    "\n",
    "1. Примените CountVectorizer с реализованным выше токенизатором к обучающим и тестовым выборкам.\n",
    "2. Обучите LogisticRegression на полученных признаках.\n",
    "3. Посчитайте метрику f1-score на тестовых данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_vec = CountVectorizer(tokenizer=mytokenize)\n",
    "x_train_transformed = my_vec.fit_transform(x_train)\n",
    "x_test_transformed = my_vec.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MaxAbsScaler()\n",
    "new_train_transformed = scaler.fit_transform(x_train_transformed)\n",
    "new_test_transformed = scaler.transform(x_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7447280799112098"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(new_train_transformed, y_train)\n",
    "f1_score(lr.predict(new_test_transformed), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 9 (1 балл)\n",
    "\n",
    "1. Повторите 7 задание, но с tf-idf векторизатором. Как изменилось качество?\n",
    "2. Мы можем еще сильнее уменьшить размер нашей матрицы, если отбросим значения df близкие к единице. Скорее всего такие слова не несут много информации о категории, так как встречаются достаточно часто. Ограничьте максимальный df в параметрах TfIdfVectorizer, поставьте верхнюю границу равную 0.9. Как изменился размер матрицы, как изменилось качество?\n",
    "3. Также мы можем уменьшить размер матрицы, удаляя слова со слишком маленьким df. Удалось ли добиться улучшения качества? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vec = TfidfVectorizer(tokenizer=mytokenize)\n",
    "x_train_transformed = tfidf_vec.fit_transform(x_train)\n",
    "x_test_transformed = tfidf_vec.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MaxAbsScaler()\n",
    "new_train_transformed = scaler.fit_transform(x_train_transformed)\n",
    "new_test_transformed = scaler.transform(x_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7457811649428416"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(new_train_transformed, y_train)\n",
    "f1_score(lr.predict(new_test_transformed), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С использованием tf-idf токенайзера качество практически не изменилось"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "↓↓↓Добавим верхнюю границу равную 0.9 в TfIdfVectorizer↓↓↓"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vec = TfidfVectorizer(tokenizer=mytokenize, max_df = 0.9)\n",
    "x_train_transformed = tfidf_vec.fit_transform(x_train)\n",
    "x_test_transformed = tfidf_vec.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MaxAbsScaler()\n",
    "new_train_transformed = scaler.fit_transform(x_train_transformed)\n",
    "new_test_transformed = scaler.transform(x_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7457811649428416"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(new_train_transformed, y_train)\n",
    "f1_score(lr.predict(new_test_transformed), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5329, 10479)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_transformed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество не изменилось, размер матрицы уменьшился примерно на 8000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "↓↓↓Попробуем ограничить слова с маленьким df↓↓↓"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vec = TfidfVectorizer(tokenizer=mytokenize, min_df = 0.0005)\n",
    "x_train_transformed = tfidf_vec.fit_transform(x_train)\n",
    "x_test_transformed = tfidf_vec.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MaxAbsScaler()\n",
    "new_train_transformed = scaler.fit_transform(x_train_transformed)\n",
    "new_test_transformed = scaler.transform(x_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7500000000000001"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(new_train_transformed, y_train)\n",
    "f1_score(lr.predict(new_test_transformed), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество улучшилось! Мы добились улучшения результата"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 10 (1 балл)\n",
    "\n",
    "Еще один популяпный трюк, который позволит уменьшить количество признаков называется hashing trick. Его суть в том, то мы случайно группируем признаки ииии  ..... складываем их! А потом удаляем исходные признаки. В итоге все наши признаки это просто суммы исходных. Звучит странно, но это отлично работает. Давайте проверим этот трюк в нашем сеттинге.\n",
    "Также при таком подходе вам не нужно хранить словарь token->index, что тоже иногда полезно.\n",
    "\n",
    "1. Повторите задание 7 с HashingVectorizer, укажите количество фичей равное 5000.\n",
    "2. Какой из подходов показал самый высокий результат?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nikita Asket\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:516: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "hash_vec = HashingVectorizer(tokenizer=mytokenize, n_features=5000)\n",
    "x_train_transformed = hash_vec.fit_transform(x_train)\n",
    "x_test_transformed = hash_vec.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MaxAbsScaler()\n",
    "new_train_transformed = scaler.fit_transform(x_train_transformed)\n",
    "new_test_transformed = scaler.transform(x_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7317862924986509"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(new_train_transformed, y_train)\n",
    "f1_score(lr.predict(new_test_transformed), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество немного уменьшилось. Самый высокий результат выдал tf-idf векторайзер, когда мы удаляли слова с маленьким df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 11 (1 балл)\n",
    "\n",
    "В этом задании нужно добиться f1 меры хотя в 0.75 на тестовых данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vec = TfidfVectorizer(tokenizer=mytokenize, min_df = 0.0005)\n",
    "x_train_transformed = tfidf_vec.fit_transform(x_train)\n",
    "x_test_transformed = tfidf_vec.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MaxAbsScaler()\n",
    "new_train_transformed = scaler.fit_transform(x_train_transformed)\n",
    "new_test_transformed = scaler.transform(x_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7500000000000001"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(new_train_transformed, y_train)\n",
    "f1_score(lr.predict(new_test_transformed), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Почти идеально 0.75)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
